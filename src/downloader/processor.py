"""
ä¸‹è½½å¤„ç†å™¨æ¨¡å—
"""

import os
import logging
import threading
from typing import Optional, List

from .config import DownloadConfig
from .utils import extract_video_id, setup_proxy
from .thread_manager import ThreadPoolManager, ThreadSafeProgress
from .video import download_segment
from .subtitle import burn_subtitles_to_video


def process_batch_urls(urls_file: str, config: DownloadConfig) -> List[dict]:
    """æ‰¹é‡å¤„ç†URLåˆ—è¡¨"""
    logger = logging.getLogger(__name__)
    results = []
    
    try:
        with open(urls_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except FileNotFoundError:
        logger.error(f"URLæ–‡ä»¶ä¸å­˜åœ¨: {urls_file}")
        return results
    
    logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(urls)} ä¸ªURL")
    
    # åˆ›å»ºçº¿ç¨‹å®‰å…¨çš„è¿›åº¦æ¡
    progress = ThreadSafeProgress(total=len(urls), desc="å¤„ç†URL", unit="ä¸ª")
    success_count = 0
    
    def process_url(url: str) -> dict:
        """å¤„ç†å•ä¸ªURLçš„åŒ…è£…å‡½æ•°"""
        nonlocal success_count
        progress.set_postfix_str(f"å½“å‰: {url[:50]}...")
        
        # ä¸ºæ¯ä¸ªURLåˆ›å»ºç‹¬ç«‹é…ç½®
        url_config = DownloadConfig(
            url=url,
            start_time=config.start_time,
            end_time=config.end_time,
            output_dir=config.output_dir,
            proxy=config.proxy,
            subtitle_langs=config.subtitle_langs,
            download_video=config.download_video,
            download_audio=config.download_audio,
            download_subtitles=config.download_subtitles,
            burn_subtitles=config.burn_subtitles,
            max_retries=config.max_retries,
            video_quality=config.video_quality,
            audio_quality=config.audio_quality
        )
        
        result = process_single_url(url_config)
        success = result is not None
        
        with threading.Lock():
            if success:
                success_count += 1
            progress.set_postfix_str(f"æˆåŠŸ: {success_count}/{len(urls)}")
            progress.update(1)
        
        return {
            'url': url,
            'success': success,
            'result': result
        }
    
    try:
        with ThreadPoolManager(max_workers=3) as pool:
            futures = [pool.executor.submit(process_url, url) for url in urls]
            results_dict = pool.wait_for_results(futures)
            results = list(results_dict.values())
    finally:
        progress.close()
    
    logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{len(urls)} ä¸ªURLæˆåŠŸ")
    return results


def process_single_url(config: DownloadConfig) -> Optional[dict]:
    """å¤„ç†å•ä¸ªURLï¼Œä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½å„ä¸ªç»„ä»¶"""
    logger = logging.getLogger(__name__)
    
    # æå–è§†é¢‘ID
    video_id = extract_video_id(config.url)
    if not video_id:
        logger.error(f"æ— æ³•ä»URLæå–è§†é¢‘ID: {config.url}")
        return None
    
    logger.info(f"ğŸ†” è§†é¢‘ID: {video_id}")
    
    # è®¾ç½®ä»£ç†
    proxy = setup_proxy(config)
    if not proxy:
        logger.error("ä»£ç†è®¾ç½®å¤±è´¥")
        return None
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config.output_dir, exist_ok=True)
    
    # ç¬¬ä¸€é˜¶æ®µï¼šå¹¶è¡Œä¸‹è½½è§†é¢‘å’Œå­—å¹•ï¼ˆé¿å…å¹¶è¡Œä¸‹è½½è§†é¢‘+éŸ³é¢‘å¯¼è‡´ 403 é”™è¯¯ï¼‰
    download_tasks = {}
    if config.download_video:
        download_tasks['video'] = ('video', video_id, proxy)
    if config.download_subtitles:
        download_tasks['subtitles'] = ('subtitles', video_id, proxy)
    
    results = {}
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½è§†é¢‘å’Œå­—å¹•
    if download_tasks:
        with ThreadPoolManager(max_workers=2) as pool:
            futures = {
                task_type: pool.executor.submit(download_segment, config, *task_args)
                for task_type, task_args in download_tasks.items()
            }
            results = pool.wait_for_results(futures)
    
    # ç¬¬äºŒé˜¶æ®µï¼šä¸‹è½½/æå–éŸ³é¢‘ï¼ˆåœ¨è§†é¢‘ä¸‹è½½å®Œæˆåï¼Œå¯ä»¥ä»è§†é¢‘ä¸­æå–éŸ³é¢‘ï¼‰
    if config.download_audio:
        logger.info("å¼€å§‹å¤„ç†éŸ³é¢‘...")
        audio_path = download_segment(config, 'audio', video_id, proxy)
        results['audio'] = audio_path
    
    # è¾“å‡ºç»“æœ
    video_dir = os.path.join(config.output_dir, video_id)
    logger.info(f"ğŸ‰ ä¸‹è½½å®Œæˆï¼æ–‡ä»¶ä¿å­˜åœ¨: {video_dir}/")
    
    for ctype, path in results.items():
        if path:
            logger.info(f"  âœ… {ctype.title()}: {os.path.basename(path)}")
        else:
            logger.warning(f"  âŒ {ctype.title()}: ä¸‹è½½å¤±è´¥")
    
    # çƒ§å½•å­—å¹•åˆ°è§†é¢‘
    if config.burn_subtitles and results.get('video') and results.get('subtitles'):
        video_path = results['video']
        subtitle_path = results['subtitles']
        
        # ç”Ÿæˆå¸¦å­—å¹•çš„è§†é¢‘æ–‡ä»¶å
        video_basename = os.path.basename(video_path)
        video_name, video_ext = os.path.splitext(video_basename)
        output_with_subs = os.path.join(video_dir, f"{video_name}_with_subs{video_ext}")
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
        if os.path.exists(output_with_subs) and os.path.getsize(output_with_subs) > 0:
            logger.info(f"âœ… å¸¦å­—å¹•çš„è§†é¢‘å·²å­˜åœ¨: {os.path.basename(output_with_subs)}")
            results['video_with_subtitles'] = output_with_subs
        else:
            # æ‰§è¡Œå­—å¹•çƒ§å½•
            burned_video = burn_subtitles_to_video(video_path, subtitle_path, output_with_subs)
            if burned_video:
                results['video_with_subtitles'] = burned_video
            else:
                logger.warning("å­—å¹•çƒ§å½•å¤±è´¥ï¼Œä¿ç•™åŸå§‹è§†é¢‘æ–‡ä»¶")
    
    return results

