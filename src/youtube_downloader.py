#!/usr/bin/env python3
"""
YouTubeä¸‹è½½å™¨ - æ”¹è¿›ç‰ˆï¼ˆå«é»˜è®¤ä»£ç†ï¼‰
æ”¯æŒæ—¶é—´æ®µè£å‰ªã€éŸ³é¢‘æå–ã€å­—å¹•ä¸‹è½½
ä½¿ç”¨ä¸¤é˜¶æ®µä¸‹è½½ç­–ç•¥ï¼šå…ˆä¸‹è½½å®Œæ•´è§†é¢‘ï¼Œå†ç²¾ç¡®åˆ‡å‰²
æŒ‰è§†é¢‘IDç»„ç»‡ä¸‹è½½çš„æ–‡ä»¶
"""

import os
import sys
import subprocess
import argparse
from datetime import datetime
import re
import glob
import shutil
import logging
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import Optional, List, Dict, Any
import time
try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False

class ThreadSafeProgress:
    """çº¿ç¨‹å®‰å…¨çš„è¿›åº¦æ¡åŒ…è£…ç±»"""
    def __init__(self, total=None, desc=None, unit=None):
        self.lock = threading.Lock()
        if HAS_TQDM:
            self.progress = tqdm(total=total, desc=desc, unit=unit)
        else:
            self.progress = None
            self.current = 0
            self.total = total
            self.desc = desc

    def update(self, n=1):
        with self.lock:
            if self.progress:
                self.progress.update(n)
            else:
                self.current += n
                if self.desc:
                    print(f"{self.desc}: {self.current}/{self.total}")

    def set_postfix_str(self, text):
        with self.lock:
            if self.progress:
                self.progress.set_postfix_str(text)
            else:
                print(f"{text}")

    def close(self):
        with self.lock:
            if self.progress:
                self.progress.close()

class ThreadPoolManager:
    """çº¿ç¨‹æ± ç®¡ç†å™¨"""
    def __init__(self, max_workers=3):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.progress_lock = threading.Lock()
        self.results_lock = threading.Lock()
        self.logger = logging.getLogger(__name__)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.executor.shutdown(wait=True)
        if exc_type:
            self.logger.error(f"çº¿ç¨‹æ± æ‰§è¡Œå‡ºé”™: {exc_val}")
            return False
        return True

    def wait_for_results(self, futures_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ç­‰å¾…å¹¶æ”¶é›†æ‰€æœ‰ä»»åŠ¡çš„ç»“æœ"""
        results = {}
        try:
            if isinstance(futures_dict, dict):
                for key, future in futures_dict.items():
                    try:
                        results[key] = future.result()
                    except Exception as e:
                        self.logger.error(f"ä»»åŠ¡ {key} æ‰§è¡Œå¤±è´¥: {e}")
                        results[key] = None
            else:  # List of futures
                for future in as_completed(futures_dict):
                    try:
                        result = future.result()
                        with self.results_lock:
                            if isinstance(result, dict):
                                results.update(result)
                            else:
                                results[id(future)] = result
                    except Exception as e:
                        self.logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
        except Exception as e:
            self.logger.error(f"ç­‰å¾…ä»»åŠ¡ç»“æœæ—¶å‡ºé”™: {e}")
        return results

@dataclass
class DownloadConfig:
    """ä¸‹è½½é…ç½®ç±»"""
    url: str
    start_time: str
    end_time: str
    output_dir: str = 'downloads'
    proxy: Optional[str] = None
    subtitle_langs: str = 'zh,en'
    download_video: bool = True
    download_audio: bool = True
    download_subtitles: bool = True
    max_retries: int = 3
    video_quality: str = 'best[height<=480]'
    audio_quality: str = '192K'

def setup_logging():
    """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('youtube_downloader.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å®‰è£…"""
    logger = logging.getLogger(__name__)
    dependencies = ['yt-dlp', 'ffmpeg']

    return True

def extract_video_id(url):
    patterns = [
        r'(?:https?://)?(?:www\.)?youtube\.com/watch\?v=([\w-]+)',
        r'(?:https?://)?(?:www\.)?youtu\.be/([\w-]+)',
        r'(?:https?://)?(?:www\.)?youtube\.com/embed/([\w-]+)'
    ]
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def parse_time(time_str):
    if ':' in time_str:
        parts = time_str.split(':')
        if len(parts) == 3:
            hours, minutes, seconds = map(int, parts)
        elif len(parts) == 2:
            hours, minutes, seconds = 0, *map(int, parts)
    else:
        total_seconds = int(time_str)
        hours = total_seconds // 3600
        minutes = (total_seconds % 3600) // 60
        seconds = total_seconds % 60
    return f"{hours:02d}:{minutes:02d}:{seconds:02d}"

def setup_proxy(config: DownloadConfig):
    """è®¾ç½®ä»£ç†é…ç½®"""
    logger = logging.getLogger(__name__)
    
    # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ä»£ç†
    if config.proxy:
        proxy = config.proxy
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
    elif os.environ.get('HTTP_PROXY') or os.environ.get('HTTPS_PROXY'):
        proxy = os.environ.get('HTTP_PROXY') or os.environ.get('HTTPS_PROXY')
        logger.info(f"ä½¿ç”¨ç¯å¢ƒå˜é‡ä»£ç†: {proxy}")
        return proxy
    # é»˜è®¤ä»£ç†ï¼ˆä»…åœ¨æœ¬åœ°å¼€å‘æ—¶ä½¿ç”¨ï¼‰
    else:
        proxy = "http://127.0.0.1:7890"
        logger.warning(f"ä½¿ç”¨é»˜è®¤ä»£ç†: {proxy} (å»ºè®®é€šè¿‡--proxyå‚æ•°æˆ–ç¯å¢ƒå˜é‡è®¾ç½®)")
    
    # éªŒè¯ä»£ç†æ ¼å¼
    if not proxy.startswith(('http://', 'https://', 'socks5://')):
        logger.error(f"æ— æ•ˆçš„ä»£ç†æ ¼å¼: {proxy}")
        return None
        
    for key in ["HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "http_proxy", "https_proxy", "all_proxy"]:
        os.environ[key] = proxy
    
    logger.info(f"ä»£ç†è®¾ç½®å®Œæˆ: {proxy}")
    return proxy

def run_command(cmd, cwd=None, max_retries=3):
    """æ‰§è¡Œå‘½ä»¤ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶"""
    logger = logging.getLogger(__name__)
    
    for attempt in range(max_retries):
        try:
            logger.debug(f"æ‰§è¡Œå‘½ä»¤ (å°è¯• {attempt + 1}/{max_retries}): {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, check=True, cwd=cwd)
            return True, result.stdout
        except subprocess.CalledProcessError as e:
            logger.warning(f"å‘½ä»¤æ‰§è¡Œå¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e.stderr}")
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                logger.error(f"å‘½ä»¤æ‰§è¡Œæœ€ç»ˆå¤±è´¥: {e.stderr}")
                return False, e.stderr
        except FileNotFoundError as e:
            logger.error(f"å‘½ä»¤ä¸å­˜åœ¨: {cmd[0]}")
            return False, f"å‘½ä»¤ä¸å­˜åœ¨: {cmd[0]}"
    
    return False, "æœªçŸ¥é”™è¯¯"

def ensure_video_dir(base_dir, video_id):
    # ç¡®ä¿ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ŒåŸºäºå½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    abs_base_dir = os.path.join(script_dir, base_dir)
    video_dir = os.path.join(abs_base_dir, video_id)
    os.makedirs(video_dir, exist_ok=True)
    return video_dir

def check_disk_space(path, required_mb=1000):
    """æ£€æŸ¥ç£ç›˜ç©ºé—´æ˜¯å¦è¶³å¤Ÿ"""
    logger = logging.getLogger(__name__)
    try:
        stat = os.statvfs(path)
        available_mb = (stat.f_bavail * stat.f_frsize) / (1024 * 1024)
        if available_mb < required_mb:
            logger.error(f"ç£ç›˜ç©ºé—´ä¸è¶³: å¯ç”¨ {available_mb:.1f}MB, éœ€è¦ {required_mb}MB")
            return False
        logger.info(f"ç£ç›˜ç©ºé—´æ£€æŸ¥é€šè¿‡: å¯ç”¨ {available_mb:.1f}MB")
        return True
    except Exception as e:
        logger.warning(f"æ— æ³•æ£€æŸ¥ç£ç›˜ç©ºé—´: {e}")
        return True  # æ£€æŸ¥å¤±è´¥æ—¶ç»§ç»­æ‰§è¡Œ

def download_subtitles(config: DownloadConfig, video_dir: str, video_id: str, proxy: str):
    """ä¸‹è½½å­—å¹•æ–‡ä»¶"""
    logger = logging.getLogger(__name__)
    logger.info("ğŸ“– å¼€å§‹ä¸‹è½½å­—å¹•...")
    
    temp_dir = os.path.join(video_dir, "temp_subs")
    os.makedirs(temp_dir, exist_ok=True)
    
    try:
        cmd = [
            'yt-dlp',
            '--proxy', proxy,
            '--cookies-from-browser', 'chrome',
            '--write-auto-sub',
            '--sub-lang', config.subtitle_langs,
            '--skip-download',
            '-o', os.path.join(temp_dir, 'subs'),
            '--no-playlist',
            config.url
        ]
        
        success, output = run_command(cmd, max_retries=config.max_retries)
        if not success:
            logger.error(f"å­—å¹•ä¸‹è½½å¤±è´¥: {output}")
            return None
            
        subtitle_files = []
        for lang in config.subtitle_langs.split(','):
            lang = lang.strip()
            pattern = os.path.join(temp_dir, f"subs.{lang}.vtt")
            matches = glob.glob(pattern)
            if matches:
                safe_start = config.start_time.replace(':', '_')
                safe_end = config.end_time.replace(':', '_')
                new_name = f"subtitles_{safe_start}-{safe_end}.{lang}.vtt"
                new_path = os.path.join(video_dir, new_name)
                shutil.move(matches[0], new_path)
                subtitle_files.append(new_path)
                logger.info(f"âœ… {lang} å­—å¹•ä¸‹è½½å®Œæˆ")
                
        if subtitle_files:
            logger.info(f"å­—å¹•ä¸‹è½½å®Œæˆ: {', '.join(os.path.basename(f) for f in subtitle_files)}")
            return subtitle_files[0]
        else:
            logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„å­—å¹•æ–‡ä»¶")
            return None
            
    except Exception as e:
        logger.error(f"å­—å¹•ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        return None
    finally:
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)

def download_and_cut_segment(config: DownloadConfig, output_path: str, content_type: str, proxy: str):
    """ä¸‹è½½å¹¶åˆ‡å‰²è§†é¢‘/éŸ³é¢‘ç‰‡æ®µ"""
    logger = logging.getLogger(__name__)
    start_str = parse_time(config.start_time)
    end_str = parse_time(config.end_time)
    temp_dir = os.path.dirname(output_path)
    temp_path = os.path.join(temp_dir, f"temp_{os.path.basename(output_path)}")
    
    try:
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        if not check_disk_space(temp_dir):
            return None
            
        # è®¾ç½®ä¸‹è½½æ ¼å¼
        if content_type == 'video':
            format_opts = ['-f', config.video_quality]
        else:
            format_opts = ['-f', 'bestaudio/best']
            
        # æ„å»ºä¸‹è½½å‘½ä»¤
        cmd = [
            'yt-dlp',
            '--proxy', proxy,
            '--cookies-from-browser', 'chrome',
            *format_opts,
            '-o', temp_path,
            '--no-playlist',
            config.url
        ]
        
        if content_type == 'audio':
            cmd.extend(['--extract-audio', '--audio-format', 'mp3', '--audio-quality', config.audio_quality])
            
        logger.info(f"å¼€å§‹ä¸‹è½½ {content_type}...")
        success, output = run_command(cmd, max_retries=config.max_retries)
        if not success:
            logger.error(f"ä¸‹è½½å¤±è´¥: {output}")
            return None
            
        # æ£€æŸ¥ä¸‹è½½çš„æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(temp_path):
            # å°è¯•æŸ¥æ‰¾å®é™…ä¸‹è½½çš„æ–‡ä»¶
            base_name = os.path.splitext(temp_path)[0]
            possible_files = glob.glob(f"{base_name}.*")
            if possible_files:
                temp_path = possible_files[0]
                logger.info(f"æ‰¾åˆ°ä¸‹è½½æ–‡ä»¶: {temp_path}")
            else:
                logger.error("ä¸‹è½½çš„æ–‡ä»¶ä¸å­˜åœ¨")
                return None
        
        # ä½¿ç”¨ffmpegåˆ‡å‰²
        logger.info(f"å¼€å§‹åˆ‡å‰² {content_type} ç‰‡æ®µ: {start_str} - {end_str}")
        if content_type == 'video':
            ffmpeg_cmd = [
                'ffmpeg', '-y', '-i', temp_path, 
                '-ss', start_str, '-to', end_str, 
                '-c:v', 'copy', '-c:a', 'copy', 
                output_path
            ]
        else:
            ffmpeg_cmd = [
                'ffmpeg', '-y', '-i', temp_path, 
                '-ss', start_str, '-to', end_str, 
                '-acodec', 'libmp3lame', '-ar', '44100', '-ab', config.audio_quality, 
                output_path
            ]
            
        success, output = run_command(ffmpeg_cmd, max_retries=2)
        if not success:
            logger.error(f"åˆ‡å‰²å¤±è´¥: {output}")
            return None
            
        logger.info(f"âœ… {content_type} å¤„ç†å®Œæˆ: {os.path.basename(output_path)}")
        return output_path
        
    except Exception as e:
        logger.error(f"å¤„ç† {content_type} æ—¶å‡ºé”™: {e}")
        return None
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for pattern in [temp_path, f"{os.path.splitext(temp_path)[0]}.*"]:
            for file_path in glob.glob(pattern):
                if os.path.exists(file_path) and file_path != output_path:
                    try:
                        os.remove(file_path)
                        logger.debug(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

def download_segment(config: DownloadConfig, content_type: str, video_id: str, proxy: str):
    """ä¸‹è½½æŒ‡å®šç±»å‹çš„åª’ä½“ç‰‡æ®µ"""
    logger = logging.getLogger(__name__)
    video_dir = ensure_video_dir(config.output_dir, video_id)
    
    safe_start = config.start_time.replace(':', '_')
    safe_end = config.end_time.replace(':', '_')
    
    if content_type == 'video':
        filename = f"segment_{safe_start}-{safe_end}.mp4"
        filepath = os.path.join(video_dir, filename)
        if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
            logger.info(f"âœ… è§†é¢‘ç‰‡æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            return filepath
        logger.info("ğŸ“¥ å¼€å§‹ä¸‹è½½å¹¶å¤„ç†è§†é¢‘ç‰‡æ®µ...")
        result = download_and_cut_segment(config, filepath, 'video', proxy)
        return result
        
    elif content_type == 'audio':
        filename = f"audio_{safe_start}-{safe_end}.mp3"
        filepath = os.path.join(video_dir, filename)
        if os.path.exists(filepath) and os.path.getsize(filepath) > 0:
            logger.info(f"âœ… éŸ³é¢‘ç‰‡æ®µå·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            return filepath
        logger.info("ğŸµ å¼€å§‹ä¸‹è½½å¹¶å¤„ç†éŸ³é¢‘ç‰‡æ®µ...")
        result = download_and_cut_segment(config, filepath, 'audio', proxy)
        return result
        
    elif content_type == 'subtitles':
        safe_start = config.start_time.replace(':', '_')
        safe_end = config.end_time.replace(':', '_')
        # æ£€æŸ¥æ‰€æœ‰é…ç½®çš„è¯­è¨€çš„å­—å¹•æ˜¯å¦éƒ½å·²å­˜åœ¨
        all_subtitles_exist = True
        for lang in config.subtitle_langs.split(','):
            lang = lang.strip()
            filename = f"subtitles_{safe_start}-{safe_end}.{lang}.vtt"
            filepath = os.path.join(video_dir, filename)
            if not (os.path.exists(filepath) and os.path.getsize(filepath) > 0):
                all_subtitles_exist = False
                break
        
        if all_subtitles_exist:
            logger.info(f"âœ… æ‰€æœ‰å­—å¹•æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½")
            return os.path.join(video_dir, f"subtitles_{safe_start}-{safe_end}.{config.subtitle_langs.split(',')[0].strip()}.vtt")
        
        return download_subtitles(config, video_dir, video_id, proxy)
        
    else:
        logger.error(f"ä¸æ”¯æŒçš„å†…å®¹ç±»å‹: {content_type}")
        return None

def load_config_file(config_path: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    import json
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        return {}
    except json.JSONDecodeError as e:
        logging.getLogger(__name__).warning(f"é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return {}

def process_batch_urls(urls_file: str, config: DownloadConfig) -> List[dict]:
    """æ‰¹é‡å¤„ç†URLåˆ—è¡¨"""
    logger = logging.getLogger(__name__)
    results = []
    
    try:
        with open(urls_file, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    except FileNotFoundError:
        logger.error(f"URLæ–‡ä»¶ä¸å­˜åœ¨: {urls_file}")
        return results
    
    logger.info(f"å¼€å§‹æ‰¹é‡å¤„ç† {len(urls)} ä¸ªURL")
    
    # åˆ›å»ºçº¿ç¨‹å®‰å…¨çš„è¿›åº¦æ¡
    progress = ThreadSafeProgress(total=len(urls), desc="å¤„ç†URL", unit="ä¸ª")
    success_count = 0
    
    def process_url(url: str) -> dict:
        """å¤„ç†å•ä¸ªURLçš„åŒ…è£…å‡½æ•°"""
        nonlocal success_count
        progress.set_postfix_str(f"å½“å‰: {url[:50]}...")
        
        # ä¸ºæ¯ä¸ªURLåˆ›å»ºç‹¬ç«‹é…ç½®
        url_config = DownloadConfig(
            url=url,
            start_time=config.start_time,
            end_time=config.end_time,
            output_dir=config.output_dir,
            proxy=config.proxy,
            subtitle_langs=config.subtitle_langs,
            download_video=config.download_video,
            download_audio=config.download_audio,
            download_subtitles=config.download_subtitles,
            max_retries=config.max_retries,
            video_quality=config.video_quality,
            audio_quality=config.audio_quality
        )
        
        result = process_single_url(url_config)
        success = result is not None
        
        with threading.Lock():
            if success:
                success_count += 1
            progress.set_postfix_str(f"æˆåŠŸ: {success_count}/{len(urls)}")
            progress.update(1)
        
        return {
            'url': url,
            'success': success,
            'result': result
        }
    
    try:
        with ThreadPoolManager(max_workers=3) as pool:
            futures = [pool.executor.submit(process_url, url) for url in urls]
            results_dict = pool.wait_for_results(futures)
            results = list(results_dict.values())
    finally:
        progress.close()
    
    logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{len(urls)} ä¸ªURLæˆåŠŸ")
    return results

def process_single_url(config: DownloadConfig) -> Optional[dict]:
    """å¤„ç†å•ä¸ªURLï¼Œä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½å„ä¸ªç»„ä»¶"""
    logger = logging.getLogger(__name__)
    
    # æå–è§†é¢‘ID
    video_id = extract_video_id(config.url)
    if not video_id:
        logger.error(f"æ— æ³•ä»URLæå–è§†é¢‘ID: {config.url}")
        return None
    
    logger.info(f"ğŸ†” è§†é¢‘ID: {video_id}")
    
    # è®¾ç½®ä»£ç†
    proxy = setup_proxy(config)
    if not proxy:
        logger.error("ä»£ç†è®¾ç½®å¤±è´¥")
        return None
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(config.output_dir, exist_ok=True)
    
    # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
    download_tasks = {}
    if config.download_video:
        download_tasks['video'] = ('video', video_id, proxy)
    if config.download_audio:
        download_tasks['audio'] = ('audio', video_id, proxy)
    if config.download_subtitles:
        download_tasks['subtitles'] = ('subtitles', video_id, proxy)
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½
    with ThreadPoolManager(max_workers=3) as pool:
        futures = {
            task_type: pool.executor.submit(download_segment, config, *task_args)
            for task_type, task_args in download_tasks.items()
        }
        results = pool.wait_for_results(futures)
    
    # è¾“å‡ºç»“æœ
    video_dir = os.path.join(config.output_dir, video_id)
    logger.info(f"ğŸ‰ ä¸‹è½½å®Œæˆï¼æ–‡ä»¶ä¿å­˜åœ¨: {video_dir}/")
    
    for ctype, path in results.items():
        if path:
            logger.info(f"  âœ… {ctype.title()}: {os.path.basename(path)}")
        else:
            logger.warning(f"  âŒ {ctype.title()}: ä¸‹è½½å¤±è´¥")
    
    return results

def main():
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging()
    
    parser = argparse.ArgumentParser(description='YouTubeä¸‹è½½å™¨ - æ”¯æŒæ—¶é—´æ®µè£å‰ªã€éŸ³é¢‘æå–ã€å­—å¹•ä¸‹è½½')
    parser.add_argument('url', nargs='?', help='YouTubeè§†é¢‘URL')
    parser.add_argument('--start', help='å¼€å§‹æ—¶é—´ (HH:MM:SS, MM:SS æˆ–ç§’æ•°)')
    parser.add_argument('--end', help='ç»“æŸæ—¶é—´ (HH:MM:SS, MM:SS æˆ–ç§’æ•°)')
    parser.add_argument('--output-dir', default='downloads', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--no-video', action='store_true', help='ä¸ä¸‹è½½è§†é¢‘')
    parser.add_argument('--no-audio', action='store_true', help='ä¸ä¸‹è½½éŸ³é¢‘')
    parser.add_argument('--no-subtitles', action='store_true', help='ä¸ä¸‹è½½å­—å¹•')
    parser.add_argument('--sub-langs', default='zh,en', help='å­—å¹•è¯­è¨€ä»£ç ')
    parser.add_argument('--proxy', help='è‡ªå®šä¹‰ä»£ç†åœ°å€ï¼Œå¦‚ http://127.0.0.1:7890')
    parser.add_argument('--batch', help='æ‰¹é‡å¤„ç†URLæ–‡ä»¶')
    parser.add_argument('--config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max-retries', type=int, default=3, help='æœ€å¤§é‡è¯•æ¬¡æ•°')
    parser.add_argument('--video-quality', default='best[height<=480]', help='è§†é¢‘è´¨é‡')
    parser.add_argument('--audio-quality', default='192K', help='éŸ³é¢‘è´¨é‡')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    config_data = {}
    if args.config:
        config_data = load_config_file(args.config)
    
    # éªŒè¯å‚æ•°
    if not args.batch and not args.url:
        logger.error("å¿…é¡»æä¾›URLæˆ–ä½¿ç”¨--batchå‚æ•°")
        parser.print_help()
        sys.exit(1)
    
    if not args.batch and (not args.start or not args.end):
        logger.error("å•ä¸ªURLæ¨¡å¼ä¸‹å¿…é¡»æä¾›--startå’Œ--endå‚æ•°")
        sys.exit(1)
    
    logger.info("ğŸ¯ YouTubeä¸‹è½½å™¨å¯åŠ¨")
    
    # åˆ›å»ºé…ç½®å¯¹è±¡
    config = DownloadConfig(
        url=args.url or '',
        start_time=args.start or config_data.get('start_time', ''),
        end_time=args.end or config_data.get('end_time', ''),
        output_dir=args.output_dir,
        proxy=args.proxy or config_data.get('proxy'),
        subtitle_langs=args.sub_langs,
        download_video=not args.no_video,
        download_audio=not args.no_audio,
        download_subtitles=not args.no_subtitles,
        max_retries=args.max_retries,
        video_quality=args.video_quality,
        audio_quality=args.audio_quality
    )
    
    try:
        if args.batch:
            # æ‰¹é‡å¤„ç†æ¨¡å¼
            results = process_batch_urls(args.batch, config)
            success_count = sum(1 for r in results if r['success'])
            logger.info(f"æ‰¹é‡å¤„ç†å®Œæˆ: {success_count}/{len(results)} ä¸ªURLæˆåŠŸ")
        else:
            # å•ä¸ªURLæ¨¡å¼
            logger.info(f"ğŸ“º URL: {config.url}")
            logger.info(f"â° æ—¶é—´æ®µ: {config.start_time} - {config.end_time}")
            process_single_url(config)
            
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()